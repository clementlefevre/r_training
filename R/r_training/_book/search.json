[{"path":"index.html","id":"about","chapter":"1 About","heading":"1 About","text":"gentle introduction data manipulation R.","code":""},{"path":"index.html","id":"prerequisite","chapter":"1 About","heading":"1.1 Prerequisite","text":"prior programming experience required. requirements :RStudio Cloud account, ’s free.strong motivation learn.time.need install software computer.","code":""},{"path":"index.html","id":"what-you-will-learn","chapter":"1 About","heading":"1.2 What you will learn","text":"end course, able :replace Excel workflow Rmanipulate different types data sources (excel, csv, json, database, pdf).create share relevant KPI (figures charts).create simple interactive Dashboard Shiny.use statistical modeling : regression, clustering.","code":""},{"path":"index.html","id":"why-this-course","chapter":"1 About","heading":"1.3 Why this course ?","text":"Quora : ever seen data scientist get fired? yes, ?’ve seen entire teams data scientists get fired replaced different type “data science” team.’ve talking paradigm shift data science multiple years now seems like now getting traction. means: companies realizing really need isn’t “data science” data practitioners. need people data savvy need tools infrastructure enable . far different classical data scientist skill set.reason took long hype waves. first wave data science made sense. dealing readily available marketing consumer data political data - easy data scientists without extremely deep subject matter expertise tackle big problems.ordinary companies (e.g manufacturing, etc) started investing much later. Many approached data scientists completely backwards. built siloed teams PhD level data scientists, gave data, expected wow stakeholders.mostly political reasons, leaders made error kept teams funded quite awhile, even knowing playground recess activity real results. fun needs end sometime, teams disbanded.mean data science fading? Absolutely . means expectations changing, organizations waking idea education data science skills won’t magically solve hardest problems.goal get organizations data-driven. develop magic machine learning model tuned every possible scenario can optimize operations 20%.progress, expect far fewer data scientists, far data engineers, far normal employees trained pieces data science skill sets. Casey McNamara - 2020.","code":""},{"path":"index.html","id":"why-r","chapter":"1 About","heading":"1.4 Why R ?","text":"","code":""},{"path":"getting-started.html","id":"getting-started","chapter":"2 Getting started","heading":"2 Getting started","text":"Start RStudio Cloud create new project : go https://rstudio.cloudsign-(can use gmail account)land start page : New Project -> New RStudio Projectyou’re good go !","code":""},{"path":"your-first-notebook.html","id":"your-first-notebook","chapter":"3 Your first notebook","heading":"3 Your first notebook","text":"","code":""},{"path":"your-first-notebook.html","id":"create-a-new-notebook","chapter":"3 Your first notebook","heading":"3.1 Create a new Notebook","text":"Rstudio Cloud project open :File -> New -> R Notebook\n(always click OK suggested install additional packages)","code":""},{"path":"your-first-notebook.html","id":"install-the-required-libraries","chapter":"3 Your first notebook","heading":"3.1.1 Install the required libraries","text":"R runs set basics functionalities, specific needs, let’s say want read Excel file, need install additional librairies (e.g. packages).\nRStudio quite straightforward : just go toRStudio -> Tools -> Install Packagestype openxlsx search bar click installRStudio automatically install package.","code":""},{"path":"your-first-notebook.html","id":"load-your-first-excel-file","chapter":"3 Your first notebook","heading":"3.2 Load your first Excel file","text":"code chunk , replace following content ::click green ᐅ icon top right code chunk.\nRStudio load package, now good read first Excel file !Code chunk, add following line :DT <- read.xlsx(\"https://r-training-bookdown.s3.amazonaws.com/data/Financial+Sample.xlsx\")code chunk look like :Click green “PLAY” iconYou see top right area notebook, Environment tab new variable DT. Just click , new View Tab pop content first Dataframe.\ncan’t believe ? Neither . OK, open favorite internet browser open following link : https://r-training-bookdown.s3.amazonaws.com/data/Financial+Sample.xlsxThis download Excel file. Open Excel. see ? table DT tab.now officially Data Scientist.","code":"\n```r\nplot(cars)\n```\n```r\nlibrary(openxlsx)\n```\n```r\nlibrary(openxlsx)\nDT <- read.xlsx(\"https://r-training-bookdown.s3.amazonaws.com/data/Financial+Sample.xlsx\")\n```"},{"path":"your-first-notebook.html","id":"exercise","chapter":"3 Your first notebook","heading":"3.2.1 Exercise","text":"Upload Excel : just click Upload button bottom right, select file click Select File (Datei Auswählen) OK.\nname file appear file explorer (bottom right screen). Make sure file contains one sheet, column names located first row. Later course show handle cases.\nLet’s assume file named report_22.xlsx. load file R, type code chunk :DT_2 <- read.xlsx(\"report_22.xlsx\")forget click green arrow code chunk execute code.see top right area notebook, Environment tab new variable DT_2. Click , new View Tab pop content Excel sheet.happy now ?","code":""},{"path":"your-first-notebook.html","id":"common-pitfalls","chapter":"3 Your first notebook","heading":"3.3 Common pitfalls","text":"R chunk (snippet code) defined :delete one ` character (backtick), RStudio recognize chunk.Every now , reset environment (Session -> Restart clear output)","code":"\n```r\n#YOUR CODE CHUNK HERE\n```"},{"path":"your-first-notebook.html","id":"how-to-read","chapter":"3 Your first notebook","heading":"3.3.1 How to read…","text":"","code":""},{"path":"your-first-notebook.html","id":"an-excel-file","chapter":"3 Your first notebook","heading":"3.3.1.1 …an Excel file","text":"Make sure adjust sheet name one sheet Excel file, also starting row index.","code":"\nlibrary(openxlsx)\nDT  <- openxlsx::read.xlsx(\"/path/to/file.xlsx\", sheet=\"the-name-of-the-sheet\",startRow=1)"},{"path":"your-first-notebook.html","id":"a-comma-separated-values-file-aka-.csv","chapter":"3 Your first notebook","heading":"3.3.1.2 …a Comma separated values file (aka .csv)","text":"Make sure adjust separator.","code":"\nlibrary(data.table)\nDT<- data.table::fread(\"/path/to/file.csv\", sep=\";\")"},{"path":"your-first-notebook.html","id":"a-json-file","chapter":"3 Your first notebook","heading":"3.3.1.3 …a Json file","text":"","code":"\nlibrary(jsonlite)\nDT<- jsonlite::fromJSON(\"https://raw.githubusercontent.com/statsbomb/open-data/master/data/competitions.json\",flatten = T)"},{"path":"data-manipulation-with-datatable.html","id":"data-manipulation-with-datatable","chapter":"4 Data manipulation with datatable","heading":"4 Data manipulation with datatable","text":"manipulate data R, two options :dplyr package. beginner friendly, tutorials can find online using dplyr.data.table package workhorse data manipulation R. introduction use , following reasons : syntax much concise dplyr, works seamlessly large dataset (like 5 millions rows). comparison, Excel can handle maximum 1,048,576 rows.","code":""},{"path":"data-manipulation-with-datatable.html","id":"workflow-with-excel","chapter":"4 Data manipulation with datatable","heading":"4.1 Workflow with Excel","text":"typical workflow Excel consists following steps :load couple Excel csv files,filter tables based given criteria,join tables (using ‘VLOOKUP’ Formula english, ‘SVERWEIS’ German, ‘RECHERCHEV’ french)select columns interestadd new columns =(A1-D4)*24save output Excel file send via email.task occurs week, R can help automatize -called “boring stuff.”\nnotebook, going achieve steps R.\nend lesson, able write script complete task automatically.\nBear .","code":""},{"path":"data-manipulation-with-datatable.html","id":"load-your-data","chapter":"4 Data manipulation with datatable","heading":"4.2 Load your data","text":"Loading input files context data manipulation means converting -called dataframe.\ndataframe nothing table, columns names rows. ’s .\nExcel file input two aspects taken :name sheet want load,index row column located.Note : deeply enshrined pathology Excel merge columns headers, take later lesson.First thing first, load necessary R packages operation : openxlsx data.table : (don’t forget click green arrow top right chunk execute code)Note: get error likeError library(data.table) : package called ‘data.table’don’t scared, ’s perfectly normal, R Project installed package yet. solve , just go Tools -> Install Packages type openxlsx (data.table) search bar, click install.\nRStudio automatically install package.download input files :Note: operation required lesson, later use filesRemember : Excel “Table” equivalent R “dataframe.”","code":"\nlibrary(openxlsx)\nlibrary(data.table)\n# create a new 'data' folder to store the files :\ndir.create(file.path(\"./data\"), showWarnings = FALSE)\n\n# download the samples files from the cloud :\ndownload.file(\"https://r-training-bookdown.s3.amazonaws.com/data/Financial+sample.xlsx\", \"./data/Financial sample.xlsx\", mode=\"wb\")\ndownload.file(\"https://r-training-bookdown.s3.amazonaws.com/data/CustomerSupport.csv\", \"./data/CustomerSupport.csv\", mode=\"wb\")"},{"path":"data-manipulation-with-datatable.html","id":"load-our-first-excel-file","chapter":"4 Data manipulation with datatable","heading":"4.3 Load our first excel file :","text":"list names sheets Excel file contains:? read excel file Financial sample.xlsx located `data folder displayed names sheets contained file. Nothing .\ncan witness eyes, Financial sample.xlsx contains two sheets : Sales ManagersNow Let’s Just Legends !© load Sales excel Sheet R dataframe :load “Sales” sheet dataframe :? just read content Sales loaded R table named DT_sales.\nNow go ","code":"\ngetSheetNames( \"./data/Financial sample.xlsx\")\n#> [1] \"Sales\"    \"Managers\"\nDT_sales <-  read.xlsx(\"./data/Financial sample.xlsx\", sheet = \"Sales\")\nDT_customer_support <- fread( \"./data/CustomerSupport.csv\")\nsetDT(DT_sales)"},{"path":"data-manipulation-with-datatable.html","id":"basic-operations","chapter":"4 Data manipulation with datatable","heading":"4.3.1 Basic operations :","text":"show dataframe structure :list Product names :get max value Profit :filter dataframe Product “Carretera” :Table 4.1: table Carretera Products.\n \nadd new column “Profit.Margin” = “Sale.Price” - “Manufacturing.Price” :","code":"\nstr(DT_sales)\n#> Classes 'data.table' and 'data.frame':   700 obs. of  16 variables:\n#>  $ Segment            : chr  \"Government\" \"Government\" \"Midmarket\" \"Midmarket\" ...\n#>  $ Country            : chr  \"Canada\" \"Germany\" \"France\" \"Germany\" ...\n#>  $ Product            : chr  \"Carretera\" \"Carretera\" \"Carretera\" \"Carretera\" ...\n#>  $ Discount.Band      : chr  \"None\" \"None\" \"None\" \"None\" ...\n#>  $ Units.Sold         : num  1618 1321 2178 888 2470 ...\n#>  $ Manufacturing.Price: num  3 3 3 3 3 3 5 5 5 5 ...\n#>  $ Sale.Price         : num  20 20 15 15 15 350 15 12 20 12 ...\n#>  $ Gross.Sales        : num  32370 26420 32670 13320 37050 ...\n#>  $ Discounts          : num  0 0 0 0 0 0 0 0 0 0 ...\n#>  $ Sales              : num  32370 26420 32670 13320 37050 ...\n#>  $ COGS               : num  16185 13210 21780 8880 24700 ...\n#>  $ Profit             : num  16185 13210 10890 4440 12350 ...\n#>  $ Date               : num  41640 41640 41791 41791 41791 ...\n#>  $ Month.Number       : num  1 1 6 6 6 12 3 6 6 6 ...\n#>  $ Month.Name         : chr  \"January\" \"January\" \"June\" \"June\" ...\n#>  $ Year               : chr  \"2014\" \"2014\" \"2014\" \"2014\" ...\n#>  - attr(*, \".internal.selfref\")=<externalptr>\nunique(DT_sales$Product)\n#> [1] \"Carretera\" \"Montana\"   \"Paseo\"     \"Velo\"     \n#> [5] \"VTT\"       \"Amarilla\"\nmax(DT_sales$Profit)\n#> [1] 262200\nDT_sales[Product==\"Carretera\"]\nDT_sales[,Profit.Margin:=(Sale.Price - Manufacturing.Price)]"},{"path":"data-manipulation-with-datatable.html","id":"pivot-table-in-r","chapter":"4 Data manipulation with datatable","heading":"4.3.2 Pivot table in R","text":"R equivalent Excel Pivot Table group operation.instance, want count number Product categories per Country :want create pivot table total number units sold per Product :Neat isn’t ?Boss© want results sorted per value. big deal :Boss© want results sorted per value, descending order :grouping data multiple columns ? Like Product Country ?Sales team needs Top 2 Sellers Countries per Product :, first copy grouped dataframe new variable DT_grouped :","code":"\nDT_sales[,.(count_Products=uniqueN(Product)), by=.(Country)]\n#>                     Country count_Products\n#> 1:                   Canada              6\n#> 2:                  Germany              6\n#> 3:                   France              6\n#> 4:                   Mexico              6\n#> 5: United States of America              6\nDT_sales[,.(total_units_sold=sum(Units.Sold)), by=.(Product)]\n#>      Product total_units_sold\n#> 1: Carretera         146846.0\n#> 2:   Montana         154198.0\n#> 3:     Paseo         338239.5\n#> 4:      Velo         162424.5\n#> 5:       VTT         168783.0\n#> 6:  Amarilla         155315.0\nDT_sales[,.(total_units_sold=sum(Units.Sold)), by=.(Product)][order(total_units_sold)]\n#>      Product total_units_sold\n#> 1: Carretera         146846.0\n#> 2:   Montana         154198.0\n#> 3:  Amarilla         155315.0\n#> 4:      Velo         162424.5\n#> 5:       VTT         168783.0\n#> 6:     Paseo         338239.5\nDT_sales[,.(total_units_sold=sum(Units.Sold)), by=.(Product)][order(-total_units_sold)]\n#>      Product total_units_sold\n#> 1:     Paseo         338239.5\n#> 2:       VTT         168783.0\n#> 3:      Velo         162424.5\n#> 4:  Amarilla         155315.0\n#> 5:   Montana         154198.0\n#> 6: Carretera         146846.0\nDT_sales[,.(total_units_sold=sum(Units.Sold)), by=.(Product, Country)]\n#>       Product                  Country total_units_sold\n#>  1: Carretera                   Canada          34804.0\n#>  2: Carretera                  Germany          24944.0\n#>  3: Carretera                   France          34056.0\n#>  4: Carretera                   Mexico          27224.0\n#>  5:   Montana                  Germany          28061.0\n#>  6:   Montana                   Canada          31488.5\n#>  7:   Montana                   France          31282.0\n#>  8:   Montana                   Mexico          31754.0\n#>  9:   Montana United States of America          31612.5\n#> 10:     Paseo                   Canada          78191.5\n#> 11:     Paseo                   Mexico          63282.0\n#> 12:     Paseo                  Germany          55693.5\n#> 13:     Paseo                   France          71606.0\n#> 14:     Paseo United States of America          69466.5\n#> 15:      Velo                   Mexico          26540.0\n#> 16:      Velo                   France          36609.5\n#> 17:      Velo                  Germany          31050.0\n#> 18:      Velo United States of America          35761.0\n#> 19:      Velo                   Canada          32464.0\n#> 20:       VTT                   Canada          41248.5\n#> 21:       VTT                  Germany          31131.0\n#> 22:       VTT                   France          35774.5\n#> 23:  Amarilla                   France          31603.0\n#> 24:  Amarilla United States of America          35469.5\n#> 25:  Amarilla                  Germany          30614.5\n#> 26: Carretera United States of America          25818.0\n#> 27:       VTT United States of America          34500.0\n#> 28:       VTT                   Mexico          26129.0\n#> 29:  Amarilla                   Mexico          28396.0\n#> 30:  Amarilla                   Canada          29232.0\n#>       Product                  Country total_units_sold\nDT_grouped <- DT_sales[,.(total_units_sold=sum(Units.Sold)), by=.(Product, Country)]\nDT_grouped[,head(.SD, 2), by=.(Product, Country)]\n#>       Product                  Country total_units_sold\n#>  1: Carretera                   Canada          34804.0\n#>  2: Carretera                  Germany          24944.0\n#>  3: Carretera                   France          34056.0\n#>  4: Carretera                   Mexico          27224.0\n#>  5:   Montana                  Germany          28061.0\n#>  6:   Montana                   Canada          31488.5\n#>  7:   Montana                   France          31282.0\n#>  8:   Montana                   Mexico          31754.0\n#>  9:   Montana United States of America          31612.5\n#> 10:     Paseo                   Canada          78191.5\n#> 11:     Paseo                   Mexico          63282.0\n#> 12:     Paseo                  Germany          55693.5\n#> 13:     Paseo                   France          71606.0\n#> 14:     Paseo United States of America          69466.5\n#> 15:      Velo                   Mexico          26540.0\n#> 16:      Velo                   France          36609.5\n#> 17:      Velo                  Germany          31050.0\n#> 18:      Velo United States of America          35761.0\n#> 19:      Velo                   Canada          32464.0\n#> 20:       VTT                   Canada          41248.5\n#> 21:       VTT                  Germany          31131.0\n#> 22:       VTT                   France          35774.5\n#> 23:  Amarilla                   France          31603.0\n#> 24:  Amarilla United States of America          35469.5\n#> 25:  Amarilla                  Germany          30614.5\n#> 26: Carretera United States of America          25818.0\n#> 27:       VTT United States of America          34500.0\n#> 28:       VTT                   Mexico          26129.0\n#> 29:  Amarilla                   Mexico          28396.0\n#> 30:  Amarilla                   Canada          29232.0\n#>       Product                  Country total_units_sold"},{"path":"data-manipulation-with-datatable.html","id":"merge-the-vlookup-variant-in-r","chapter":"4 Data manipulation with datatable","heading":"4.3.3 Merge, the VLOOKUP variant in R","text":"One common operation Excel combine two tables, based specific column.","code":""},{"path":"data-manipulation-with-datatable.html","id":"export-the-result-as-an-excel-file","chapter":"4 Data manipulation with datatable","heading":"4.3.4 Export the result as an Excel file :","text":"download file, just check box besides filename (DT_grouped.xlsx) file explorer (bottom right) -> exportUseful resources learn data.table :https://cran.r-project.org/web/packages/data.table/vignettes/datatable-intro.htmlhttps://franknarf1.github.io/r-tutorial/_book/tables.html#tables","code":"\nwrite.xlsx(DT_grouped, \"DT_grouped.xlsx\", sheetName=\"grouped Sales\")"},{"path":"visualization-with-ggplot2.html","id":"visualization-with-ggplot2","chapter":"5 Visualization with ggplot2","heading":"5 Visualization with ggplot2","text":"https://www.r-graph-gallery.com/","code":""},{"path":"first-assignment.html","id":"first-assignment","chapter":"6 First assignment","heading":"6 First assignment","text":"","code":""},{"path":"first-assignment.html","id":"the-big-picture","chapter":"6 First assignment","heading":"6.1 The big picture","text":"Last year biggest untapped Bitcoin deposit discovered Burkina Faso.\nThomas Sankara Sovereign Found commissioned assess new investment opportunities field football. Due material reasons (allocated budget disappeared somewhere Zurich Basel), able make -site visits Europeans clubs. Nevertheless, Found, infinite kindness, created Gmail account , allow access RStudio Cloud, powerful analysis tool world (Cross-multiplication, course).scope study Spanish Liga 1, use StatsBomb data.\nmay now aware , due financial limitations project, free datasets available study. Don’t sad, still lot fun dataset !can find raw data ./data folder running code chunk :[Hint : real iconoclast, start look documentation]order able add title Senior Data Scientist TikTok profile, must first prove extent skills. let’s start basic calculations.Using ./data/DT_all_matches.csv file, compute following informations :first last date matches.eldest youngest manager times. [Hint: look lubridate* package easily manipulate dates]eldest youngest manager per season.Team biggest home scores times.Team biggest away scores per season.name referee participated matches seasons.list Teams took part one season.*SFWGiven results, put money ?got money ?","code":"\n# This chunk downloads the Statsbomb data.You need to run this script once, then you can set the `update_data` variable to `FALSE`\n\nlibrary(data.table)\nupdate_data <- TRUE\n\nif (update_data) {\n  download.file(\"https://r-training-bookdown.s3.amazonaws.com/data/data.zip\", dest = \"data.zip\", mode = \"wb\")\n  unzip(\"data.zip\", exdir = \".\")\n  file.remove(\"data.zip\")\n}\n#> [1] TRUE\nDT_matches <- fread(\"./data/DT_all_matches.csv\")\n#DT_matches[, .N, by = .(season.season_name)]\n# You wonderfully crafted code goes here..."},{"path":"first-assignment.html","id":"data-scientist-but-also-part-time-visual-designer","chapter":"6 First assignment","heading":"6.2 Data Scientist, but also part-time Visual Designer","text":"read ggplot2 introduction, now able plot nice charts impress Board.plot number Home Score per Team Season 2017/2018 (order per Number Home Scores) [Hint : use geom_bar function]plot number Home Score per Team Season 2017/2018 (order per Number Home Scores) [Hint : use geom_bar function]plot timeline home scores Betis Sevilla seasons matches. [see ]plot timeline home scores Betis Sevilla seasons matches. [see ]plot Distribution Home Away Scores seasons [Hint: boxplot pretty good job]plot Distribution Home Away Scores seasons [Hint: boxplot pretty good job]pimping charts ggtheme make instagrammable ?","code":""},{"path":"first-assignment.html","id":"merging-and-acquisition","chapter":"6 First assignment","heading":"6.3 Merging and Acquisition","text":"Now real fun starts. start combining matches data lineups., expect basic understanding merge (Excel community, think VLOOKUP, SQL staff think JOIN)merge matches lineups table match_id value.check number rows newly datatable number lineups’rows.Let’s Just Legends !","code":"\nDT_lineups <- fread(\"./data/DT_all_lineups_players.csv\", encoding = \"UTF-8\")\n# merge example :\n# df_merged <-  merge(df1, df2, by.x = \"df1ColName\", by.y = \"df2ColName\")"},{"path":"references.html","id":"references","chapter":"References","heading":"References","text":"","code":""}]
